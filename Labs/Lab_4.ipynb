{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP LAB 4: Semántica Léxica con Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download() #collections->identifier=book & name=Everything used in the NLTK book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn #importamos wordnet (que usa synsets, palabras sinónimas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog') #todos los synstes de una palabra (y ordenados por frecuencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chase.v.01')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog', pos=wn.VERB) #solo mostrame los verbos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01')\n",
      "Synset('frump.n.01')\n",
      "Synset('frump.n.01')\n"
     ]
    }
   ],
   "source": [
    "#Entendiendo frump.n.01\n",
    "print(wn.synset('dog.n.01'))\n",
    "print(wn.synset('dog.n.02')) #dog.n.02 == frump.n.01 !\n",
    "print(wn.synset('frump.n.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "\n",
      "a dull unattractive unpleasant girl or woman\n",
      "\n",
      "a dull unattractive unpleasant girl or woman\n"
     ]
    }
   ],
   "source": [
    "#Veamos las definiciones\n",
    "print(wn.synset('dog.n.01').definition())\n",
    "print(\"\\n\"+ wn.synset('dog.n.02').definition())\n",
    "print(\"\\n\"+ wn.synset('frump.n.01').definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
      "[Lemma('frump.n.01.frump'), Lemma('frump.n.01.dog')]\n"
     ]
    }
   ],
   "source": [
    "#Sinónimos de un synset\n",
    "print(wn.synset('dog.n.01').lemmas())\n",
    "print(wn.synset('dog.n.02').lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the dog barked all night']\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo de uso del synset\n",
    "print(wn.synset('dog.n.01').examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'domestic_dog', 'Canis_familiaris']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Los nombres de cada sinónimo\n",
    "[str(lemma.name()) for lemma in wn.synset('dog.n.01').lemmas()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtener hiperónimos\n",
    "wn.synset('dog.n.01').hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('basenji.n.01'),\n",
       " Synset('corgi.n.01'),\n",
       " Synset('cur.n.01'),\n",
       " Synset('dalmatian.n.02'),\n",
       " Synset('great_pyrenees.n.01'),\n",
       " Synset('griffon.n.02'),\n",
       " Synset('hunting_dog.n.01'),\n",
       " Synset('lapdog.n.01'),\n",
       " Synset('leonberg.n.01'),\n",
       " Synset('mexican_hairless.n.01'),\n",
       " Synset('newfoundland.n.01'),\n",
       " Synset('pooch.n.01'),\n",
       " Synset('poodle.n.01'),\n",
       " Synset('pug.n.01'),\n",
       " Synset('puppy.n.01'),\n",
       " Synset('spitz.n.01'),\n",
       " Synset('toy_dog.n.01'),\n",
       " Synset('working_dog.n.01')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtener hipónimos\n",
    "wn.synset('dog.n.01').hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('bad.a.01.bad')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Antónimos de una palabra\n",
    "good = wn.synset('good.a.01').lemmas()[0] #tomamos el primer lemma (’good.a.01.good’) del synset\n",
    "good.antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('flag.n.07')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Obtener merónimos (subparte)\n",
    "dog = wn.synset('dog.n.01')\n",
    "print(dog.part_meronyms())\n",
    "print(dog.member_meronyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[Synset('canis.n.01'), Synset('pack.n.06')]\n"
     ]
    }
   ],
   "source": [
    "#Obtener holónimos (\"super\"-parte)\n",
    "print(dog.part_holonyms())\n",
    "print(dog.member_holonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a conspicuously marked or shaped tail\n",
      "type genus of the Canidae: domestic and wild dogs; wolves; jackals\n",
      "a group of hunting animals\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio: analizar por qué flag.n.07, canis.n.01 y pack.n.06 están relacionados con perro\n",
    "print(wn.synset('flag.n.07').definition()) #se refiere/relaciona a la cola, una subparte del perro\n",
    "print(wn.synset('canis.n.01').definition()) #habla del género de los cánidos, superparte del perro\n",
    "print(wn.synset('pack.n.06').definition()) #grupo de animales cazadores, superparte del perro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desambiguación de palabras por sentido\n",
    "#Algoritmo de Lesk (1)\n",
    "#1. Extraer las palabras del contexto\n",
    "#2. Comparar con las definiciones/ejemplos del diccionario para obtener los distintos sentidos\n",
    "#3. Elegir el sentido que mejor matchee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bank.n.01'),\n",
       " Synset('depository_financial_institution.n.01'),\n",
       " Synset('bank.n.03'),\n",
       " Synset('bank.n.04'),\n",
       " Synset('bank.n.05'),\n",
       " Synset('bank.n.06'),\n",
       " Synset('bank.n.07'),\n",
       " Synset('savings_bank.n.02'),\n",
       " Synset('bank.n.09'),\n",
       " Synset('bank.n.10')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ejercicio: ¿Cuántos sentidos crees que tiene la palabra bank? Por lo menos 5.\n",
    "wn.synsets('bank', pos=wn.NOUN) #Un poco mas que 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a financial institution that accepts deposits and channels the money into lending activities'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The bank can guarantee deposits will eventually cover future tuition costs because it invests\n",
    "#in adjustable-rate mortgage securities\n",
    "#¿Qué synset es el sentido correcto para la palabra en el contexto de la oración anterior?\n",
    "wn.synset('depository_financial_institution.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bank.n.05')\n"
     ]
    }
   ],
   "source": [
    "#Mismo análisis con el algoritmo de Lesk\n",
    "from nltk.wsd import lesk\n",
    "from nltk import word_tokenize\n",
    "S = \"The bank can guarantee deposits will eventually cover future tuition costs because it invests in adjustable-rate mortgage securities.\"\n",
    "S_tok = word_tokenize(S)\n",
    "print(lesk(S_tok, 'bank', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a supply or stock held in reserve for future use (especially in emergencies)'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lesk asume erroneamente Synset('bank.n.05') que es\n",
    "wn.synset('bank.n.05').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asumo que porque en la oración se encuentran las palabras \"depositar\" y \"futuro\" que aparecen\n",
    "#en la definición o están relacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'supply', 'or', 'stock', 'held', 'in', 'reserve', 'for', 'future', 'use', '(', 'especially', 'in', 'emergencies', ')']\n",
      "['a', 'financial', 'institution', 'that', 'accepts', 'deposits', 'and', 'channels', 'the', 'money', 'into', 'lending', 'activities']\n",
      "{'in', 'future'}\n",
      "{'deposits'}\n"
     ]
    }
   ],
   "source": [
    "l = word_tokenize((wn.synset('bank.n.05').definition()))\n",
    "print(l)\n",
    "m = word_tokenize((wn.synset('bank.n.02').definition()))\n",
    "print(m)\n",
    "k = set(S_tok)\n",
    "print(k.intersection(l)) \n",
    "#Hay mayor intersección con bank.n.05, y eso es lo que la implementación de Lesk usa para decidir\n",
    "print(k.intersection(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¿Qué cambios, de haber alguno, sugeriría para la correspondencia implementada por NLTK?\n",
    "#Para empezar diría eliminar las stopwords ya que \"in\" no es realmente algo que ayude a decidir\n",
    "#Otras ideas podrían ser buscar palabras similares y analizar ejemplos de uso de la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio: para cada ejemplo, a continuación descubra el sentido correcto de WordNet según\n",
    "#su criterio. Puede usar la búsqueda en línea de WordNet para navegar a través de los\n",
    "#sentidos. http://wordnetweb.princeton.edu/perl/webwn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a container (usually with a slot in the top) for keeping money at home\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the bank to deposit some money.\"\n",
    "sentence_tok = word_tokenize(sentence)\n",
    "#Wordnet: bank=depository financial institution\n",
    "print(lesk(sentence_tok, 'bank', 'n').definition()) # ✘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a meal eaten in a mess hall by service personnel\n"
     ]
    }
   ],
   "source": [
    "sentence = \"She created a big mess of the birthday cake.\"\n",
    "sentence_tok = word_tokenize(sentence)\n",
    "#Wordnet: mess=a state of confusion and disorderliness\n",
    "print(lesk(sentence_tok, 'mess', 'n').definition()) # ✘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of being certain that adverse effects will not be caused by some agent under defined conditions\n"
     ]
    }
   ],
   "source": [
    "sentence = \"In the interest of your safety, please wear your seatbelt.\"\n",
    "sentence_tok = word_tokenize(sentence)\n",
    "#Wordnet: safety=the state of being certain that adverse effects will not be caused by some agent under defined conditions\n",
    "print(lesk(sentence_tok, 'safety', 'n').definition()) # ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "having a low or inadequate temperature or feeling a sensation of coldness or having been made cold by e.g. ice or refrigeration\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I drank some ice cold water.\"\n",
    "sentence_tok = word_tokenize(sentence)\n",
    "#Wordnet: cold=having a low or inadequate temperature or feeling a sensation of coldness or having been made cold by e.g. ice or refrigeration\n",
    "print(lesk(sentence_tok, 'cold', 'a').definition()) # ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para estas oraciones obtuve una precisión del 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "walk\n"
     ]
    }
   ],
   "source": [
    "#Lematizar palabras\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnLemmatizer = WordNetLemmatizer()\n",
    "print(wnLemmatizer.lemmatize('dogs', 'n')) #si no agregás el segundo argumento defaultea a noun\n",
    "print(wnLemmatizer.lemmatize('walking', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('went', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('bank', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('deposit', 'VB'),\n",
       " ('some', 'DT'),\n",
       " ('money', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POS tagging\n",
    "nltk.pos_tag(word_tokenize(\"I went to the bank to deposit some money.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio final: ¿Podrías mejorar el algoritmo de Lesk con un lematizador? Si es así, \n",
    "#¿podrías escribir una función de match, que tome dos cadenas y devuelva las palabras\n",
    "#coincidentes entre ellas? Queremos que las coincidencias(matches) sean útiles para un\n",
    "#algoritmo como Lesk. ¿Quizás también necesites usar un etiquetador POS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    #Mapeo de tags de nltk a wordnet\n",
    "    #https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lem_pos_match(s1,s2):\n",
    "    #Takes in two sentences and does lemmatization + POS to match the words between them\n",
    "    #returns an array with the matched words e.g. [eat,run,goodbye]\n",
    "    #TODO: remove stopwords !\n",
    "    #TODO: lower all the text before intersecting?\n",
    "    s1_t_pos = nltk.pos_tag(word_tokenize(s1))\n",
    "    s2_t_pos = nltk.pos_tag(word_tokenize(s2))\n",
    "    s1_lem = [WordNetLemmatizer().lemmatize(t_pos[0],get_wordnet_pos(t_pos[1])) for t_pos in s1_t_pos]\n",
    "    s2_lem = [WordNetLemmatizer().lemmatize(t_pos[0],get_wordnet_pos(t_pos[1])) for t_pos in s2_t_pos]\n",
    "    return list(set(s1_lem).intersection(set(s2_lem)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'car', 'buy']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_pos_match(\"I'm buying a car\",\"My friend bought a car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['live']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_pos_match(\"A life worth living\",\"Do you live to work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laboratorio realizado a partir del pdf NLP UTN Lab 4 del profesor Hernán Borré"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) CE314/CE887 Lecture 7: Word Sense Disambiguation, Aline Villavicencio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
